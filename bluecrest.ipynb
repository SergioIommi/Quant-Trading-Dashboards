{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4398466d-d69c-494a-a007-a026a0b7dc2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T15:24:40.639442Z",
     "iopub.status.busy": "2023-08-08T15:24:40.639129Z",
     "iopub.status.idle": "2023-08-08T15:24:40.650832Z",
     "shell.execute_reply": "2023-08-08T15:24:40.650217Z",
     "shell.execute_reply.started": "2023-08-08T15:24:40.639417Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sergio/work/misc/bluecrest_2023-07/project',\n",
       " '/home/sergio/anaconda3/envs/py38_bluecrest3/lib/python38.zip',\n",
       " '/home/sergio/anaconda3/envs/py38_bluecrest3/lib/python3.8',\n",
       " '/home/sergio/anaconda3/envs/py38_bluecrest3/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/sergio/.local/lib/python3.8/site-packages',\n",
       " '/home/sergio/anaconda3/envs/py38_bluecrest3/lib/python3.8/site-packages']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5313cb-5c63-4e60-8d9b-7143b965a97d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T15:24:40.922431Z",
     "iopub.status.busy": "2023-08-08T15:24:40.922209Z",
     "iopub.status.idle": "2023-08-08T15:24:41.121598Z",
     "shell.execute_reply": "2023-08-08T15:24:41.121116Z",
     "shell.execute_reply.started": "2023-08-08T15:24:40.922411Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# General notebook configuration:\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 200\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Pretty print all cell's output and not just the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Auto-reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c465d8e6-ca00-4644-8224-684c5653b7cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DatabaseBackendMongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "560171ee-bda3-497f-901d-47d5db845ab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T13:23:20.261993Z",
     "iopub.status.busy": "2023-08-08T13:23:20.261053Z",
     "iopub.status.idle": "2023-08-08T13:24:05.273971Z",
     "shell.execute_reply": "2023-08-08T13:24:05.273271Z",
     "shell.execute_reply.started": "2023-08-08T13:23:20.261963Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and populating collection in database\n",
      "Downloading data from Yahoo Finance\n",
      "Downloading data for symbol WVE (symbol 1 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol WW (symbol 2 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol WWW (symbol 3 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol WY (symbol 4 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol WYNN (symbol 5 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XAIR (symbol 6 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XEL (symbol 7 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XERS (symbol 8 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XFOR (symbol 9 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XHR (symbol 10 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XMTR (symbol 11 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XNCR (symbol 12 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XOM (symbol 13 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XOMA (symbol 14 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XPEL (symbol 15 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XPER (symbol 16 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XPOF (symbol 17 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XPRO (symbol 18 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XRAY (symbol 19 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XRX (symbol 20 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol XYL (symbol 21 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol YELP (symbol 22 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol YEXT (symbol 23 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol YMAB (symbol 24 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol YORW (symbol 25 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol YOU (symbol 26 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol YUM (symbol 27 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZBH (symbol 28 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZBRA (symbol 29 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZD (symbol 30 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZETA (symbol 31 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZEUS (symbol 32 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZIMV (symbol 33 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZION (symbol 34 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZIP (symbol 35 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZM (symbol 36 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZNTL (symbol 37 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZS (symbol 38 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZTS (symbol 39 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZUMZ (symbol 40 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZUO (symbol 41 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZURA (symbol 42 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZVIA (symbol 43 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZVRA (symbol 44 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZWS (symbol 45 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZYME (symbol 46 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ZYXI (symbol 47 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ^GSPC (symbol 48 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ^NDX (symbol 49 of 2519) from date 2022-01-01\n",
      "Downloading data for symbol ^RUT (symbol 50 of 2519) from date 2022-01-01\n",
      "Inserting data in database\n",
      "Inserted 19486 records into the collection\n",
      "last modified 2023-08-08 13:24:05.264206\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import yfinance as yf\n",
    "\n",
    "class DatabaseBackendMongoDB():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 db_params: dict,\n",
    "                 stock_data_params: dict):\n",
    "        # Declare class parameters storing database URI, database name and database-collection name\n",
    "        self.db_uri = db_params['db_uri']\n",
    "        self.db_name = db_params['db_name']\n",
    "        self.db_collection_name = db_params['db_collection_name']\n",
    "        \n",
    "        # Declare class parameters storing list of stock indices, start-date (for initial date to download data) and local path storing CSVs containing stock symbols\n",
    "        self.stock_indices = stock_data_params['stock_indices']\n",
    "        self.start_date_creation = stock_data_params['start_date_creation']\n",
    "        self.path_csv_symbols = stock_data_params['path_csv_symbols']\n",
    "\n",
    "    def run_database_backend(self):\n",
    "        try:\n",
    "            # Connect to MongoDB\n",
    "            self.client = pymongo.MongoClient(self.db_uri)\n",
    "            \n",
    "            # Check if stocks database and collection exists in MongoDB, if it exists it means we have already created and populated it with some initial data,\n",
    "            # so this function call is to update/replenish the data, otherwise this is the inital call so we need to download the initial data and store it in the database.\n",
    "            if self.db_name in self.client.list_database_names():  # check if database name for stocks exists in MongoDB\n",
    "                # Get database containing stocks data\n",
    "                self.db = self.client[self.db_name]\n",
    "                if self.db_collection_name in self.db.list_collection_names():  # check if collection for daily data exists in stocks database\n",
    "                    # Update collection in database\n",
    "                    self.update_database()\n",
    "            else:\n",
    "                # Create database containing stocks data\n",
    "                self.db = self.client[self.db_name]\n",
    "                # Create and populate collection in database\n",
    "                self.create_database()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while connecting and creating/updating the database: {e}\")\n",
    "        finally:\n",
    "            # Close connection to database\n",
    "            self.client.close()\n",
    "            \n",
    "    def create_database(self):\n",
    "        print('Creating and populating collection in database')\n",
    "        \n",
    "        # Load symbols for stock indices from CSVs stored in folder '.../symbols' and create a dictionary\n",
    "        # index_symbols_dict:\n",
    "        #   {'GSPC': ['AAPL', 'GOOG', ...],\n",
    "        #    'NDX': [...]\n",
    "        #    ...}\n",
    "        index_symbols_dict = dict()\n",
    "        for index in self.stock_indices:\n",
    "            index_symbols = pd.read_csv(os.path.join(self.path_csv_symbols,f'{index}.csv'))\n",
    "            index_symbols_dict[index] = list(index_symbols['Symbol'])\n",
    "\n",
    "        # Create pandas dataframe with symbols as rows and stock indices as columns with true (false) boolean value if symbol is (is not) among constituents of specific stock index.\n",
    "        # This is required to avoid storing duplicate data on the database (same stock for different stock indices).\n",
    "        # index_symbols_bool_df:\n",
    "        #        GSPC  NDX   RUT\n",
    "        #   AAPL True True False\n",
    "        #   ...\n",
    "        values = list(set([ x for y in index_symbols_dict.values() for x in y]))\n",
    "        data = {}\n",
    "        for key in index_symbols_dict.keys():\n",
    "            data[key] = [True if value in index_symbols_dict[key] else False for value in values]\n",
    "        index_symbols_bool_df = pd.DataFrame(data, index=values).sort_index()\n",
    "        index_symbols_bool_df.index.name = 'Symbol'\n",
    "        # Save resulting dataframe as CSV (index_symbols_bool.csv) in folder '.../symbols' for later use when we need to update the database. This is done for efficiency reasons: avoid recreating such\n",
    "        # table or reading the database to extract the list of unique symbols every time we update the database with new data.\n",
    "        index_symbols_bool_df.to_csv(os.path.join(self.path_csv_symbols,'index_symbols_bool.csv'))\n",
    "\n",
    "        # Download (from Yahoo Finance)\n",
    "        data = self.download_transform_data(start_date = self.start_date_creation,\n",
    "                                            index_symbols_bool_df=index_symbols_bool_df)\n",
    "\n",
    "        # Write data to database\n",
    "        self.write_data_to_database(data=data)\n",
    "\n",
    "    def update_database(self):\n",
    "        print('Updating collection in database')\n",
    "        \n",
    "        # Query database to get last stored date for each symbol\n",
    "        # Get collection storing stocks data\n",
    "        db_collection = self.db[self.db_collection_name]\n",
    "        # Get last date for each symbol\n",
    "        cursor = db_collection.aggregate([{'$group': {'_id': \"$Ticker\", 'Date': {'$last': '$Date'}}}])\n",
    "        symbols_last_date_df = pd.DataFrame(list(cursor))\n",
    "        # Get most recent date in the database and add 1 day to download from that date (to avoid duplicates). I assume the data for all the stocks in the collection has been downloaded up to the last\n",
    "        # date for all of them.\n",
    "        #TODO: Add a check to make sure that the above is true.\n",
    "        start_date_update = symbols_last_date_df['Date'].max() + pd.DateOffset(1)\n",
    "        \n",
    "        # get index_symbols_bool_df from CSV file 'index_symbols_bool.csv' generated and saved at the time of the database creation\n",
    "        index_symbols_bool_df = pd.read_csv(os.path.join(self.path_csv_symbols,'index_symbols_bool.csv')).set_index(keys='Symbol', drop=True)\n",
    "        \n",
    "        # Download (from Yahoo Finance)\n",
    "        data_update = self.download_transform_data(start_date = start_date_update,\n",
    "                                                   index_symbols_bool_df=index_symbols_bool_df)\n",
    "\n",
    "        # Write data to database\n",
    "        self.write_data_to_database(data=data_update)\n",
    "\n",
    "    def download_transform_data(self,\n",
    "                                start_date: str or datetime,  # string (YYYY-MM-DD) or datetime\n",
    "                                index_symbols_bool_df: pd.DataFrame):\n",
    "        print('Downloading data from Yahoo Finance')\n",
    "        all_data = pd.DataFrame()  # dataframe containing data for all stocks\n",
    "        symbol_data_list = []\n",
    "        index_symbols = index_symbols_bool_df.columns\n",
    "        num_symbols = len(index_symbols_bool_df.index)\n",
    "\n",
    "        #for i, symbol in enumerate(index_symbols_bool_df.index[-50:],1):  # test for downloading only a subset of 50 stocks\n",
    "        for i, symbol in enumerate(index_symbols_bool_df.index,1):\n",
    "            try:\n",
    "                print(f'Downloading data for symbol {symbol} (symbol {i} of {num_symbols}) from date {start_date}')\n",
    "                # Retrieve stock data for symbol\n",
    "                symbol_yf = yf.Ticker(symbol)\n",
    "                symbol_data = symbol_yf.history(start=start_date,\n",
    "                                                actions=False)\n",
    "                # Add column with symbol\n",
    "                symbol_data.insert(0, 'Symbol', symbol)\n",
    "                # Add name of company/stock index\n",
    "                symbol_data.insert(1, 'Name', symbol_yf.info['longName'])\n",
    "                # Add column with date\n",
    "                #symbol_data.insert(2, 'Date', symbol_data.index.tz_localize(None))\n",
    "                symbol_data.insert(2, 'Date', symbol_data.index)\n",
    "                # Add one column for each stock index and set value to true (false) if symbol is (is not) among constituents of specific stock index\n",
    "                #symbol_data.loc[:,index_symbols] = list(index_symbols_bool_df.loc[symbol,:])\n",
    "                cols = [f'Index_{index_symbol}' for index_symbol in index_symbols]\n",
    "                symbol_data.loc[:,cols] = list(index_symbols_bool_df.loc[symbol,:])\n",
    "                # Append data to dataframe containing data for all stocks\n",
    "                all_data = pd.concat([all_data, symbol_data])\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while retrieving data for {symbol} from Yahoo Finance: {e}\")\n",
    "        \n",
    "        return all_data\n",
    "    \n",
    "    def write_data_to_database(self,\n",
    "                               data: pd.DataFrame):\n",
    "        print('Inserting data in database')\n",
    "        \n",
    "        # Transform data from dataframe to list of dictionaries to make it compatible for writing into MongoDB\n",
    "        data_dict = data.to_dict(orient='records')\n",
    "\n",
    "        try:\n",
    "            # Get/create collection for specific type of stocks data (daily, monthly, etc.)\n",
    "            db_collection = self.db[self.db_collection_name]\n",
    "\n",
    "            # Insert/update data into the collection\n",
    "            result = db_collection.insert_many(data_dict,\n",
    "                                               ordered=True)\n",
    "            print(f\"Inserted {len(result.inserted_ids)} records into the collection\")\n",
    "            print(f\"last modified {datetime.datetime.utcnow()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while inserting data into the database: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    stock_data_params = {'stock_indices': ['GSPC', 'NDX', 'RUT'],\n",
    "                         #'start_date_creation': '2020-01-01',\n",
    "                         'start_date_creation': '2022-01-01',\n",
    "                         'path_csv_symbols': f\"{os.path.abspath('')}/symbols\"}\n",
    "    db_params={'db_uri': 'mongodb://localhost:27017/',\n",
    "               'db_name': 'stocks_db',\n",
    "               'db_collection_name': 'daily'}\n",
    "    db_backend_instance = DatabaseBackendMongoDB(db_params=db_params,\n",
    "                                                 stock_data_params=stock_data_params)\n",
    "    db_backend_instance.run_database_backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e73fd-ad0e-4101-aee0-8066131778ce",
   "metadata": {},
   "source": [
    "# Project-1: Equities Pairs Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ae65e3-87c4-4af5-a980-60a0fa29829e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T15:37:49.232853Z",
     "iopub.status.busy": "2023-08-08T15:37:49.232397Z",
     "iopub.status.idle": "2023-08-08T15:37:49.635437Z",
     "shell.execute_reply": "2023-08-08T15:37:49.634414Z",
     "shell.execute_reply.started": "2023-08-08T15:37:49.232814Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc6359c4e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dash import Dash, dcc, Input, Output, State, callback, no_update, dash_table\n",
    "import dash_mantine_components as dmc\n",
    "import plotly.express as px\n",
    "import pymongo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "from pykalman import KalmanFilter\n",
    "import quantstats as qs\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "db_params={'db_uri': 'mongodb://localhost:27017/',\n",
    "           'db_name': 'stocks_db',\n",
    "           'db_collection_name': 'daily'}\n",
    "db_uri = db_params['db_uri']\n",
    "db_name = db_params['db_name']\n",
    "db_collection_name = db_params['db_collection_name']\n",
    "        \n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(db_uri)\n",
    "db = client[db_name]\n",
    "db_collection = db[db_collection_name]\n",
    "\n",
    "def get_db_min_max_dates(min_max_str='min'):\n",
    "    \"\"\"\n",
    "    Get min/max dates stored in database\n",
    "    \"\"\"\n",
    "    cursor = db_collection.find({},\n",
    "                                {'_id':    0,\n",
    "                                 'Date':   1,\n",
    "                                })\n",
    "    query_result = list(cursor)\n",
    "    db_dates = pd.DataFrame(query_result)\n",
    "    if min_max_str == 'min':\n",
    "        return db_dates['Date'].min().date()\n",
    "    elif min_max_str == 'max':\n",
    "        return db_dates['Date'].max().date()\n",
    "\n",
    "def get_data(date_start, date_end):\n",
    "    \"\"\"\n",
    "    Get data from database\n",
    "    \"\"\"\n",
    "    date_end = date_end+datetime.timedelta(days=1)  # increment 1 day to include the day in the query, otherwise it is discarded by MongoDB\n",
    "    cursor = db_collection.find({'Date': {'$gt': date_start,\n",
    "                                          '$lt': date_end\n",
    "                                         }\n",
    "                                },\n",
    "                                {'_id':    0,\n",
    "                                 'Date':   1,\n",
    "                                 'Symbol': 1,\n",
    "                                 'Close': 1\n",
    "                                })\n",
    "    query_result = list(cursor)\n",
    "\n",
    "    # Build pandas dataframe with stocks data got from database (structure it to have name of column containing closing price for specific stock, equal to the symbol of the stock)\n",
    "    # ex. \n",
    "    #    Date  (df index)       XEL          ZM           ZS => stock symbols \n",
    "    #    2023-07-25 04:00:00    64.959999    69.330002    155.210007\n",
    "    #    2023-07-26 04:00:00    65.050003    71.099998    156.619995\n",
    "    #    2023-07-27 04:00:00    62.869999    72.389999    155.250000\n",
    "    #    2023-07-28 04:00:00    62.889999    73.080002    157.490005\n",
    "    #    2023-07-31 04:00:00    62.730000    73.349998    160.380005\n",
    "    #    2023-08-01 04:00:00    62.930000    72.485001    163.940002\n",
    "    #\n",
    "    data_stocks_query = pd.DataFrame(query_result)\n",
    "    gb = data_stocks_query.groupby('Symbol')\n",
    "    data_stocks = pd.DataFrame()\n",
    "    for x in gb.groups:\n",
    "        if data_stocks.empty:\n",
    "            df_temp = gb.get_group(x)\n",
    "            df_temp = df_temp.rename(columns={'Close': df_temp['Symbol'].iloc[0]})\n",
    "            df_temp.drop(columns=['Symbol'], inplace=True)\n",
    "            data_stocks = df_temp\n",
    "            del df_temp\n",
    "        else:\n",
    "            df_temp = gb.get_group(x)\n",
    "            df_temp = df_temp.rename(columns={'Close': df_temp['Symbol'].iloc[0]})\n",
    "            df_temp.drop(columns=['Symbol'], inplace=True)\n",
    "            data_stocks = pd.merge(data_stocks, df_temp, on='Date', how='outer')\n",
    "            del df_temp\n",
    "    data_stocks.set_index('Date', inplace=True)\n",
    "    return data_stocks\n",
    "\n",
    "\n",
    "def select_pairs_correlation(data_stocks, n_pairs_to_select=5):\n",
    "    \"\"\"\n",
    "    Select the stock pairs with the highest correlation\n",
    "    \"\"\"\n",
    "    # n_pairs_to_select: variable to specify the number of the most highly correlated pairs to select\n",
    "    \n",
    "    # In this step I pre-select the most highly correlated pirs of stocks (including stock indices as well) to later compute the model for the mean-reverting spread (using OLS regression or the\n",
    "    #    Kalman filter for a state-space model) only on the these selected pairs. The main aim of this procedure is to reduce the computational time/costs and avoid estimating models for pairs that aren't\n",
    "    #    promising candidates.\n",
    "\n",
    "    # Compute correlation matrix (matrix containing correlation for each pair of stocks) and convert it to a more usable format to select the top correlated pairs according to absolute correlation\n",
    "    #    ex.\n",
    "    #        SymbolA  SymbolB  Corr       AbsCorr   SignCorr\n",
    "    #    0   ^GSPC    ^NDX     0.972411   0.972411  1.0\n",
    "    #    1   ZD       ZIP      0.949294   0.949294  1.0\n",
    "    #    2   ZEUS     ^RUT     0.942167   0.942167  1.0\n",
    "    #    3   YELP     ^RUT     0.930411   0.930411  1.0\n",
    "    #    4   WY       ZD       0.923649   0.923649  1.0\n",
    "    corr = data_stocks.corr(method='pearson')\n",
    "    corr = corr.where(np.triu(np.ones(corr.shape)).astype(bool))\n",
    "    corr = corr.stack().reset_index()\n",
    "    corr.columns = ['SymbolA','SymbolB','Corr']\n",
    "    corr = corr[corr['SymbolA'] != corr['SymbolB']]\n",
    "    corr['AbsCorr'] = corr['Corr'].abs()\n",
    "    corr['SignCorr'] = np.sign(corr['Corr'])\n",
    "    corr.sort_values('AbsCorr', inplace=True, ascending=False)\n",
    "    corr.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Select most highly correlated pairs\n",
    "    selected_pairs = corr.iloc[0:n_pairs_to_select]\n",
    "\n",
    "    return selected_pairs\n",
    "    \n",
    "\n",
    "def half_life(spread):\n",
    "    \"\"\"\n",
    "    Compute the half-life of the spread model which is an auto-regressive AR(1) model\n",
    "    https://mathtopics.wordpress.com/2013/01/10/half-life-of-the-ar1-process/\n",
    "    \"\"\"\n",
    "    spread_lag = spread.shift(1)\n",
    "    spread_lag.iloc[0] = spread_lag.iloc[1]\n",
    "    spread_ret = spread - spread_lag\n",
    "    spread_ret.iloc[0] = spread_ret.iloc[1]\n",
    "    spread_lag2 = sm.add_constant(spread_lag)\n",
    "    model = sm.OLS(spread_ret, spread_lag2)\n",
    "    res = model.fit()\n",
    "    halflife = int(round(-np.log(2) / res.params[1],0))\n",
    "    if halflife <= 0:\n",
    "        halflife = 1\n",
    "    return halflife\n",
    "\n",
    "    \n",
    "def estimate_spread_model(data_stocks, selected_model, selected_pairs):\n",
    "    \"\"\"\n",
    "    Estimate the parameters alpha/beta for the spread model (Spread = StockB - beta*StockA - alpha) with one of the following 2 models/methods:\n",
    "        - linear regression model with OLS estimator (beta/alpha fixed): Spread_t = StockB_t - beta*StockA_t - alpha (t=time)\n",
    "        - state-space model with Kalman filter estimation algorithm (beta_t/alpha_t dynamic): Spread_t = StockB_t - beta_t*StockA_t - alpha_t (t=time)\n",
    "    \"\"\"\n",
    "    # Build a nested dictionary to store the information related to each of the selected pairs (symbols, correlation, half-life/speed of mean reversion, parameters of the OLS/Kalman filter models to estimate, etc.)\n",
    "    selected_pairs_dict = dict()\n",
    "    for i, row in selected_pairs.iterrows():\n",
    "        selected_pairs_dict[f'Pair_{i}'] = {'SymbolA': row['SymbolA'],\n",
    "                                            'SymbolB': row['SymbolB'],\n",
    "                                            'Corr': row['Corr'],\n",
    "                                            'Half-Life': None\n",
    "                                            }\n",
    "\n",
    "        # Build Model for the (Mean-Reverting) Spread of the form (t=time):\n",
    "        #        OLS Linear Regression:  Spread_t = PriceStockA_t - beta * PriceStockA_t - alpha\n",
    "        #        SSM with Kalman Filter: Spread_t = PriceStockA_t - beta_t * PriceStockA_t - alpha_t\n",
    "        # The main difference between the 2 models is that the parameters of the OLS Linear Regression are fixed meanwhile the ones estimated using the Kalman Filter (in the state-space modelling framework) are\n",
    "        # dynamic and change in time\n",
    "\n",
    "        # I use directly the prices to estimate the regression model but other approaches could be tested as well (log prices, returns, etc.)\n",
    "        #x = np.log(data_stocks[row['SymbolA']])\n",
    "        x = data_stocks[row['SymbolA']]\n",
    "        #y = np.log(data_stocks[row['SymbolB']])\n",
    "        y = data_stocks[row['SymbolB']]\n",
    "        \n",
    "        # Fill NANs by forward filling\n",
    "        x.ffill(inplace=True)\n",
    "        y.ffill(inplace=True)\n",
    "        \n",
    "        # Make sure the dataframes for the stocks have the same samples to avoid problems in the estimation of the models\n",
    "        # Convert series to dataframe\n",
    "        x = x.to_frame()\n",
    "        y = y.to_frame()\n",
    "        x.reset_index(inplace=True)\n",
    "        y.reset_index(inplace=True)\n",
    "        # Inner merge to have same dates between the 2 series of prices\n",
    "        x = pd.merge(x, y[['Date']], how='inner', on='Date')\n",
    "        y = pd.merge(x[['Date']], y, how='inner', on='Date')\n",
    "        # Set 'Date' as index on both dataframes\n",
    "        x.set_index('Date', inplace=True)\n",
    "        y.set_index('Date', inplace=True)\n",
    "        # Convert back to series\n",
    "        x = x.squeeze()\n",
    "        y = y.squeeze()\n",
    "\n",
    "        if selected_model == 'ols':\n",
    "            # First estimate OLS linear regression model to get alpha and beta using the prices of the 2 selected stocks/stock indices. The alpha and beta will be used to build the model for the spread.\n",
    "            x_const = sm.add_constant(x)  # add constant to predictor variable\n",
    "            model = sm.OLS(y, x_const, missing='drop').fit()\n",
    "            # Get OLS parameters\n",
    "            alpha = model.params[0]\n",
    "            beta = model.params[1]\n",
    "        elif selected_model =='kalman':\n",
    "            # Estimate a model for the spread (for the prices of the 2 selected stocks/stock indices) directly by making use of a state-space modelling approach and estimating the alpha\n",
    "            # and beta of the spread model by using a Kalam filter.\n",
    "            obs_mat = sm.add_constant(x.values, prepend=False)[:, np.newaxis]\n",
    "            delta = 1e-5\n",
    "            trans_cov = delta / (1 - delta) * np.eye(2)\n",
    "            kf = KalmanFilter(n_dim_obs=1,  # y is 1-dimensional\n",
    "                              n_dim_state=2,  # (alpha, beta) is 2-dimensional\n",
    "                              initial_state_mean=np.ones(2),\n",
    "                              initial_state_covariance=np.ones((2, 2)),\n",
    "                              transition_matrices=np.eye(2),\n",
    "                              observation_matrices=obs_mat,\n",
    "                              observation_covariance=0.5,\n",
    "                              transition_covariance=trans_cov)\n",
    "            state_means, state_covs = kf.filter(y.values)\n",
    "            alpha=state_means[:, 1]\n",
    "            beta=state_means[:, 0]\n",
    "        # Build the spread time-series using the parameters alpha/beta estimated via OLS/Kalman Filter and store it as a pandas dataframe\n",
    "        # This spread, hopefully mean-reverting, can be used as the main input to build the signal for the trading strategy later on\n",
    "        df_spread = pd.DataFrame(y - x*beta - alpha, index = data_stocks.index)\n",
    "        df_spread.columns = ['spread']\n",
    "        # Store the resulting spread in the selected_pairs_dict dictionary. I serialize the dataframe to JSON to share it between Dash callbacks (using dcc.Store).\n",
    "        selected_pairs_dict[f'Pair_{i}']['spread'] = df_spread['spread'].to_json()\n",
    "        # Compute half-life/speed of mean reversion and add it to selected_pairs_dict dictionary\n",
    "        selected_pairs_dict[f'Pair_{i}']['Half-Life'] = half_life(df_spread)\n",
    "        # Store beta which is equal to the hedge-ratio (to compute the strategy returns in the backtesting)\n",
    "        if isinstance(beta, np.ndarray):\n",
    "            beta = beta.tolist()  # Convert numpy ndarray to list to make it serializable to JSON to share it between Dash callbacks (using dcc.Store).\n",
    "        selected_pairs_dict[f'Pair_{i}']['Beta'] = beta\n",
    "        # Store the the prices for both stocks in the selected_pairs_dict dictionary (to be used later for computing the backtests). I could have queried them again from the database in the later steps\n",
    "        # and avoid duplicate data, but I prefer storing them in the dictionary and then in the browser session (in memory) for simplicity and with the assumption that the number of selected pairs aren't\n",
    "        # that big. I serialize the dataframes as JSON to share them between Dash callbacks (using dcc.Store).\n",
    "        selected_pairs_dict[f'Pair_{i}']['x'] = data_stocks[row['SymbolA']].to_json()\n",
    "        selected_pairs_dict[f'Pair_{i}']['y'] = data_stocks[row['SymbolB']].to_json()\n",
    "        \n",
    "    return selected_pairs_dict\n",
    "\n",
    "\n",
    "def run_backtest(selected_pairs_dict, zscore_entry = 1.5, zscore_exit = 0):\n",
    "    \"\"\"\n",
    "    Run simple backtest on each of the selected stock pairs and compute:\n",
    "        - time-series of the cumulative returns\n",
    "        - Sharpe ratio\n",
    "        - CAGR (compound annual growth rate)\n",
    "    \"\"\"\n",
    "    for key, pair in selected_pairs_dict.items():\n",
    "        # Deserialize JSON pandas series stored in dict (loaded from dcc.Store)\n",
    "        df_backtest = pd.read_json(pair['spread'], typ='series').to_frame('spread')\n",
    "        # To compute the returns of the strategy we need to compute the actual change in the spread, and to do that we need the 'beta' of the estimated models and the prices of the 2 stocks used to build the spread\n",
    "        df_backtest['beta'] = pair['Beta']\n",
    "        # Deserialize JSON pandas series stored in dict (loaded from dcc.Store)\n",
    "        df_backtest['x'] = pd.read_json(pair['x'], typ='series').to_frame('x')\n",
    "        df_backtest['y'] = pd.read_json(pair['y'], typ='series').to_frame('y')\n",
    "        epsilon = 1e-6  # small value to be used in the divisions to make sure we don't divide by zero\n",
    "\n",
    "        # The core of the trading strategy is the alpha signal, which in this case it the z-score of the spread (or the z-score normalized spread):\n",
    "        #    z-score(spread) = ( spread - mean(spread) ) / std(spread)\n",
    "        # I use the z-score of the spread instead of the actual spread as the input of the alpha signal because each pair of stocks could have a spread with a standard deviation that\n",
    "        # is rather different, hence the entry and exit (that are based on how 'far' we move away from the spread mean) for the trading strategy would need to be adapted for each pair of stocks.\n",
    "        # By using the z-score instead the spread is 'normalized' so that the entry and exit for each pair can be compared across all the pairs, and in particular the range of values for the entry\n",
    "        # and exit proposed to the user (with 2 sliders in the GUI) can be the same for all pairs.\n",
    "        # In particular there are few possibilities to compure the z-score, a dynamic one which uses the rolling_mean and rolling_std (with a time-window of predefined width), or a fixed vcersion\n",
    "        # with the mean and std computed over the entire period.\n",
    "        # In a normal setting of designing a trading strategy for live trading, using the rolling version is to be preferred because it is dynamic and it is more suited to adapt to changing market\n",
    "        # regimes. With a fixed mean and std computed over historical data there could be the problem that they're unable to capture new market regimes (in terms of these 2 statistics) and there\n",
    "        # would be the need for some monitoring and an actual discretionary decision (from a quant trader/researcher) as to when update the mean and std used in the computation of the z-score to\n",
    "        # account for the new market regime observed.\n",
    "        \n",
    "        # In the following I use a fixed z-score with fixed mean and std.\n",
    "        # Someting to underline is the fact that by using these values I introduce a look-ahead bias in the trading strategies, hence the results of the backtests have to be discounted for this.\n",
    "        # For this specific project I consider it ok given that the goal isn't that of building full proof trading strategies to be deployed live but to evaluate other skillsets.\n",
    "        spread_mean = df_backtest['spread'].mean()\n",
    "        spread_std  = df_backtest['spread'].std()\n",
    "        # For completeness, I leave the code to compute the rolling window z-score of the spread (with window width equal to half-life period)\n",
    "        #halflife = pair['Half-Life']\n",
    "        #spread_mean = df_backtest['spread'].rolling(window=halflife).mean()\n",
    "        #spread_std  = df_backtest['spread'].rolling(window=halflife).std()\n",
    "        \n",
    "        # Compute the z-score\n",
    "        df_backtest['zscore'] = (df_backtest['spread'] - spread_mean) / (spread_std + epsilon)\n",
    "        # Save z-score on dictionary for plotting later\n",
    "        selected_pairs_dict[key]['zscore'] = df_backtest['zscore'].to_json()\n",
    "\n",
    "        # Longs:\n",
    "        # Compute the instant/day when we open/close each long:\n",
    "        df_backtest['long_open'] = np.where(np.logical_and(df_backtest['zscore'] < -zscore_entry, df_backtest['zscore'].shift(1) > -zscore_entry), True, False)\n",
    "        df_backtest['long_close'] = np.where(np.logical_and(df_backtest['zscore'] > -zscore_exit, df_backtest['zscore'].shift(1) < -zscore_exit), True, False)\n",
    "        # Compute for each instant/day if a long position is open or not (1 for open long position and 0 for no-long position)\n",
    "        df_backtest['long_position'] = np.where(df_backtest['long_open'], 1,\n",
    "                                      (np.where(df_backtest['long_close'], 0, np.nan)))\n",
    "        df_backtest['long_position'] = df_backtest['long_position'].ffill().fillna(0)\n",
    "\n",
    "        # Shorts:\n",
    "        # Compute the instant/day when we open/close each short\n",
    "        df_backtest['short_open'] = np.where(np.logical_and(df_backtest['zscore'] > zscore_entry, df_backtest['zscore'].shift(1) < zscore_entry), True, False)\n",
    "        df_backtest['short_close'] = np.where(np.logical_and(df_backtest['zscore'] < zscore_exit, df_backtest['zscore'].shift(1) > zscore_exit), True, False)\n",
    "        # Compute for each instant/day if a short position is open or not (1 for open short position and 0 for no-short position)\n",
    "        df_backtest['short_position'] = np.where(df_backtest['short_open'], -1,\n",
    "                                       (np.where(df_backtest['short_close'], 0, np.nan)))\n",
    "        df_backtest['short_position'] = df_backtest['short_position'].ffill().fillna(0)\n",
    "\n",
    "        # Compute trading strategy return\n",
    "        df_backtest['long_short_position'] = df_backtest['long_position'] + df_backtest['short_position']\n",
    "        df_backtest['spread_change_pct'] = (df_backtest['spread'] - df_backtest['spread'].shift(1)) / ((df_backtest['x'] * abs(df_backtest['beta'])) + df_backtest['y'])\n",
    "        df_backtest['return'] = df_backtest['spread_change_pct'] * df_backtest['long_short_position'].shift(1)\n",
    "        df_backtest['return'].fillna(0, inplace=True)\n",
    "        start_portfolio_value = 1\n",
    "        df_backtest['cumulative_return'] = start_portfolio_value + df_backtest['return'].cumsum()\n",
    "        # Save cumulative return on dictionary for plotting later\n",
    "        selected_pairs_dict[key]['cumulative_return'] = df_backtest['cumulative_return'].to_json()\n",
    "\n",
    "        # Compute Sharpe ratio\n",
    "        sharpe = np.round(np.sqrt(252) * df_backtest['return'].mean() / ( df_backtest['return'].std() + epsilon ), 2)\n",
    "\n",
    "        # Compute CAGR (compound annual growth rate)\n",
    "        end_portfolio_value = df_backtest['cumulative_return'].iloc[-1]\n",
    "        trading_days = (df_backtest.index[-1].date() - df_backtest.index[0].date()).days\n",
    "        cagr = (end_portfolio_value / start_portfolio_value) ** (252/trading_days) - 1\n",
    "\n",
    "        # Update dictionary with Sharpe and CAGR\n",
    "        selected_pairs_dict[key]['Sharpe'] = sharpe\n",
    "        selected_pairs_dict[key]['CAGR (%)'] = np.round(cagr*100,1)\n",
    "        \n",
    "    return selected_pairs_dict\n",
    "\n",
    "def run_backtest_details(df_cumret):\n",
    "    \"\"\"\n",
    "    Run detailed backtest on each of the selected stock pairs to compute few risk/return metrics\n",
    "    \"\"\"\n",
    "    # Compute risk-return metrics and store them in a pandas dataframe\n",
    "    data = [qs.stats.cagr(df_cumret)*100,\n",
    "            qs.stats.sharpe(df_cumret),\n",
    "            qs.stats.sortino(df_cumret),\n",
    "            qs.stats.max_drawdown(df_cumret)*100,\n",
    "            qs.stats.volatility(df_cumret)*100,\n",
    "            qs.stats.skew(df_cumret),\n",
    "            qs.stats.kurtosis(df_cumret)\n",
    "           ]\n",
    "    data = [np.round(value,2) for value in data]\n",
    "    index=['CAGR (%)',\n",
    "           'Sharpe',\n",
    "           'Sortino',\n",
    "           'Max Drawdown (%)',\n",
    "           'Volatility (%)',\n",
    "           'Skew',\n",
    "           'Kurtosis']\n",
    "    risk_return_metrics = pd.DataFrame(data=data,\n",
    "                                       index=index,\n",
    "                                       columns=['Risk-Return Metrics'])\n",
    "    \n",
    "    risk_return_metrics\n",
    "    risk_return_metrics.reset_index(inplace=True)\n",
    "    risk_return_metrics.rename(columns={'index': 'Risk-Return Metrics', 'Risk-Return Metrics': 'Value'}, inplace=True)\n",
    "    \n",
    "    return risk_return_metrics\n",
    "\n",
    "\n",
    "models_to_select = [['ols', 'OLS Linear Regression'], ['kalman', 'Kalman Filter (State-Space Model)']]\n",
    "    \n",
    "app.layout = dmc.MantineProvider(\n",
    "    theme={\n",
    "        \"primaryColor\": \"indigo\",\n",
    "        \"components\": {\n",
    "            \"Button\": {\"styles\": {\"root\": {\"fontWeight\": 400}}},\n",
    "            \"Alert\": {\"styles\": {\"title\": {\"fontWeight\": 500}}},\n",
    "            \"AvatarGroup\": {\"styles\": {\"truncated\": {\"fontWeight\": 500}}},\n",
    "         },\n",
    "    },\n",
    "    inherit=True,\n",
    "    withGlobalStyles=True,\n",
    "    withNormalizeCSS=True,\n",
    "    children=[\n",
    "    # To share data between Dash callbacks I initialise the dcc.Store to store JSON data in the browser session (in memory)\n",
    "    dcc.Store(id='browser-session-memory-storage', storage_type='memory'),\n",
    "    dmc.Space(h=20),\n",
    "    dmc.Grid([\n",
    "        dmc.Col([dmc.Title(f\"Equities Pair-Trading\", order=4),\n",
    "                 dmc.DateRangePicker(id=\"date-range-picker\",\n",
    "                                     label=\"Select date range (max interval pre-selected):\",\n",
    "                                     minDate=get_db_min_max_dates(min_max_str='min'),\n",
    "                                     maxDate=get_db_min_max_dates(min_max_str='max'),\n",
    "                                     value=[get_db_min_max_dates(min_max_str='min'), get_db_min_max_dates(min_max_str='max')],\n",
    "                                     style={\"width\": 300},\n",
    "                                     clearable=False,\n",
    "                                    ),\n",
    "                 dmc.Space(h=10),\n",
    "                 dmc.RadioGroup([dmc.Radio(l, value=k) for k, l in models_to_select],\n",
    "                                id=\"model-selector\",\n",
    "                                #value='ols',\n",
    "                                label=\"Select model to estimate alpha/beta for the spread \\n(Spread = StockB - beta*StockA - alpha):\",\n",
    "                                size=\"sm\",\n",
    "                                mt=10,\n",
    "                                style={\"width\": 270,\n",
    "                                       \"white-space\": \"pre\"},\n",
    "                               ),\n",
    "                 dmc.Space(h=10),\n",
    "                 dmc.Alert(\"Estimating Models! Please wait.\",\n",
    "                           id='model-estimation-alert',\n",
    "                           title=\"INFO\",\n",
    "                           color=\"yellow\",\n",
    "                           hide=True),\n",
    "                 dmc.Space(h=10),\n",
    "                 dmc.Alert(\"Unfortunately there was a problem in \\nestimating the models probably for a lack of data \\nfor some symbols. Please try changing the \\ndate-interval (making it wider or moving it).\",\n",
    "                            id='model-estimation-exception-alert',\n",
    "                            title=\"ALERT!\",\n",
    "                            color=\"red\",\n",
    "                            duration=5000,\n",
    "                            hide=True,\n",
    "                            style={\"width\": 350,\n",
    "                                   \"white-space\": \"pre\"}),\n",
    "                 dmc.Space(h=10),\n",
    "                 dash_table.DataTable(id='correlation-table',\n",
    "                                      style_data={'whiteSpace': 'normal',\n",
    "                                                  'height': 'auto',\n",
    "                                                  'lineHeight': '15px'\n",
    "                                                 },\n",
    "                                     ),\n",
    "                ], span=2, offset=0.25),\n",
    "        dmc.Col([\n",
    "            dmc.Text(\"Select Z-Score entry/exit values (1.5 and 0 preselected are suggested as starting ones):\", align=\"left\", size=\"lg\"),\n",
    "            dmc.Space(h=10),\n",
    "            dmc.Text(\"Select Z-Score entry value:\", align=\"left\", size=\"sm\"),\n",
    "            dmc.Slider(id=\"drag-slider-zscore-entry\",\n",
    "                       min=0,\n",
    "                       max=3,\n",
    "                       step=0.1,\n",
    "                       value=1.5,\n",
    "                       updatemode=\"drag\",\n",
    "                       marks=[{\"value\": value, 'label': f'{value}'} for value in np.arange(0,3.1,0.5)]+[{\"value\": value} for value in np.arange(0,3.1,0.1)]\n",
    "                      ),\n",
    "            dmc.Space(h=20),\n",
    "            dmc.Text(id='drag-slider-zscore-entry-output', align=\"left\", size=\"sm\"),\n",
    "            dmc.Space(h=20),\n",
    "            dmc.Text(\"Select Z-Score trade exit value (must be smaller than entry Z-Score):\", align=\"left\", size=\"sm\"),\n",
    "            dmc.Slider(id=\"drag-slider-zscore-exit\",\n",
    "                       min=0,\n",
    "                       max=3,\n",
    "                       step=0.1,\n",
    "                       value=0,\n",
    "                       updatemode=\"drag\",\n",
    "                       marks=[{\"value\": value, 'label': f'{value}'} for value in np.arange(0,3.1,0.5)]+[{\"value\": value} for value in np.arange(0,3.1,0.1)]\n",
    "                      ),\n",
    "            dmc.Space(h=20),\n",
    "            dmc.Text(id='drag-slider-zscore-exit-output', align=\"left\", size=\"sm\"),\n",
    "            dmc.Space(h=10),\n",
    "            dmc.Alert(\"Selected ZScore exit > ZScore entry! Please check and update the values selected.\",\n",
    "                      id='drag-slider-zscore-exit-alert',\n",
    "                      title=\"ALERT!\",\n",
    "                      color=\"red\",\n",
    "                      hide=True),\n",
    "            dmc.Space(h=10),\n",
    "            dmc.Text(id='backtest-table-descr', align=\"left\", size=\"sm\"),\n",
    "            dash_table.DataTable(id='backtest-table',\n",
    "                                 #style_as_list_view=True,\n",
    "                                 row_selectable='single',\n",
    "                                 selected_rows=[],\n",
    "                                 style_data={'whiteSpace': 'normal',\n",
    "                                             'height': 'auto',\n",
    "                                             'lineHeight': '15px'\n",
    "                                            },\n",
    "                                ),\n",
    "        ], span=3, offset=0.5),\n",
    "        dmc.Col([\n",
    "            dmc.Text(id='backtest-details-table-descr', children='', align=\"left\", size=\"sm\"),\n",
    "            dash_table.DataTable(id='backtest-details-table',\n",
    "                                 data=[],\n",
    "                                 columns=[],\n",
    "                                 #style_as_list_view=True,\n",
    "                                 style_data={'whiteSpace': 'normal',\n",
    "                                             'height': 'auto',\n",
    "                                             'lineHeight': '15px',\n",
    "                                            },\n",
    "                                ),\n",
    "            dcc.Graph(figure={}, id=\"cumulative-return-plot\"),\n",
    "            dcc.Graph(figure={}, id=\"zscore-plot\"),\n",
    "        ], span=5, offset=0.5),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(Output(\"model-estimation-alert\", \"hide\"),\n",
    "              Output('backtest-table-descr', 'children', allow_duplicate=True),\n",
    "              Output('backtest-table', 'data', allow_duplicate=True),\n",
    "              Output('backtest-table', 'columns', allow_duplicate=True),\n",
    "              Output('backtest-details-table-descr', 'children', allow_duplicate=True),\n",
    "              Output('backtest-details-table', 'data', allow_duplicate=True),\n",
    "              Output('backtest-details-table', 'columns', allow_duplicate=True),\n",
    "              Output('zscore-plot', 'figure', allow_duplicate=True),\n",
    "              Output('cumulative-return-plot', 'figure', allow_duplicate=True),\n",
    "              Input(\"model-selector\", \"value\"),\n",
    "              State(\"model-selector\", \"value\"),\n",
    "              State(\"model-estimation-alert\", \"hide\"),\n",
    "              prevent_initial_call=True)\n",
    "def model_estimation_alert_callback(selected_model, previous_selected_model, hide_model_estimation_alert):\n",
    "    if hide_model_estimation_alert == True and (selected_model or selected_model != previous_selected_model):\n",
    "        # Clear all the dash items that need a refresh\n",
    "        return not hide_model_estimation_alert, [], [], [], [], [], [], {}, {}\n",
    "\n",
    "    \n",
    "@app.callback(Output('browser-session-memory-storage', 'data'),\n",
    "              Output('correlation-table', 'data'),\n",
    "              Output('correlation-table', 'columns'),\n",
    "              Output(\"model-estimation-alert\", \"hide\", allow_duplicate=True),\n",
    "              Output(\"model-estimation-exception-alert\", \"hide\"),\n",
    "              State('date-range-picker', 'value'),\n",
    "              Input('model-selector', 'value'),\n",
    "              State(\"model-estimation-exception-alert\", \"hide\"),\n",
    "              prevent_initial_call=True)\n",
    "def select_stocks_callback(selected_dates, selected_model, hide_model_exception_alert):\n",
    "    date_start, date_end = selected_dates\n",
    "    date_format = '%Y-%m-%d'\n",
    "    date_start = datetime.datetime.strptime(date_start, date_format)\n",
    "    date_end = datetime.datetime.strptime(date_end, date_format)\n",
    "    \n",
    "    # Get the stocks data from the database soon as the user select the date-range and the model estimation method (OLS or Kalman). If the user is going to change the model once already selected there will be\n",
    "    # another query to the database to get the same initial data. This could be separated in a different Dash callback but the approaches (described here https://dash.plotly.com/sharing-data-between-callbacks)\n",
    "    # to then share this data betweek callbacks could be less efficient than a new query to the database, and given the performance of MongoDB and the small amount of data to query (daily vs intraday) my approach\n",
    "    # is probably better. That said, the approaches suggested by Dash could be explored and tested.\n",
    "    # That said, I have used the dcc.Store to store JSON data in the browser session (in memory) to share other data between other callbacks of this application.\n",
    "    data_stocks = get_data(date_start, date_end)\n",
    "    \n",
    "    selected_pairs = select_pairs_correlation(data_stocks=data_stocks,\n",
    "                                              n_pairs_to_select=10)\n",
    "    \n",
    "    try:\n",
    "        selected_pairs_dict = estimate_spread_model(data_stocks=data_stocks,\n",
    "                                                    selected_model=selected_model,\n",
    "                                                    selected_pairs=selected_pairs)\n",
    "\n",
    "        # Build table with relevant data for stock pairs and convert to format compatible for dash_table.DataTable\n",
    "        selected_pairs_df = pd.DataFrame()\n",
    "        for dict_ in selected_pairs_dict.values():\n",
    "            dict_selected_keys = {key: [dict_[key]] for key in ['SymbolA', 'SymbolB', 'Corr', 'Half-Life']}\n",
    "            df_temp = pd.DataFrame.from_dict(dict_selected_keys)\n",
    "            selected_pairs_df = selected_pairs_df.append(df_temp)\n",
    "        selected_pairs_df.reset_index(inplace=True, drop=True)\n",
    "        selected_pairs_df = selected_pairs_df.round(3)\n",
    "        selected_pairs_dash_table_data = selected_pairs_df.to_dict('records')\n",
    "        selected_pairs_dash_table_columns = [{\"name\": i, \"id\": i} for i in selected_pairs_df.columns]\n",
    "\n",
    "        # I return the data I need to share with the trading strategy backtester (callback run_backtest_callback) to store it in the browser session.\n",
    "        # The data is in a dictionary so I don't need to serialise it in JSON beforehand (apart from the pandas dataframes that are already serialized\n",
    "        # to JSON at the time I created the dictionary).\n",
    "        hide_model_estimation_alert=True\n",
    "        hide_model_exception_alert=True\n",
    "        return selected_pairs_dict, selected_pairs_dash_table_data, selected_pairs_dash_table_columns, hide_model_estimation_alert, hide_model_exception_alert\n",
    "    except:\n",
    "        hide_model_estimation_alert=True\n",
    "        hide_model_exception_alert = False\n",
    "        return [], [], [], hide_model_estimation_alert, hide_model_exception_alert\n",
    "\n",
    "\n",
    "@app.callback(Output(\"drag-slider-zscore-entry-output\", \"children\"),\n",
    "          Input(\"drag-slider-zscore-entry\", \"value\")\n",
    ")\n",
    "def zscore_entry_callback(zscore_entry):\n",
    "    return f\"Selected value: {np.round(zscore_entry,2)}\"\n",
    "\n",
    "\n",
    "@app.callback(Output(\"drag-slider-zscore-exit-output\", \"children\"),\n",
    "          Input(\"drag-slider-zscore-exit\", \"value\")\n",
    ")\n",
    "def zscore_exit_callback(zscore_exit):\n",
    "    return f\"Selected value: {np.round(zscore_exit,2)}\"\n",
    "\n",
    "\n",
    "@app.callback(Output(\"drag-slider-zscore-exit-alert\", \"hide\"),\n",
    "              Input(\"drag-slider-zscore-entry\", \"value\"),\n",
    "              Input(\"drag-slider-zscore-exit\", \"value\"),\n",
    "              State(\"drag-slider-zscore-exit-alert\", \"hide\"),\n",
    "              prevent_initial_call=True)\n",
    "def zscore_alert_callback(zscore_entry, zscore_exit, hide):\n",
    "    # Show alert in case of invalid selection of ZScore values\n",
    "    if hide == True and zscore_entry <= zscore_exit:\n",
    "        return not hide\n",
    "    elif hide == False and zscore_entry > zscore_exit:\n",
    "        return not hide\n",
    "    else:\n",
    "        return hide\n",
    "\n",
    "    \n",
    "@app.callback(Output('browser-session-memory-storage', 'data', allow_duplicate=True),\n",
    "              Output('backtest-table-descr', 'children'),\n",
    "              Output('backtest-table', 'data'),\n",
    "              Output('backtest-table', 'columns'),\n",
    "              Input('browser-session-memory-storage', 'data'),\n",
    "              Input(\"drag-slider-zscore-entry\", \"value\"),\n",
    "              Input(\"drag-slider-zscore-exit\", \"value\"),\n",
    "              prevent_initial_call=True)\n",
    "def run_backtest_callback(selected_pairs_dict, zscore_entry, zscore_exit):\n",
    "    # Run basic backtest only for valid values selected for the z-score entry/exit\n",
    "    if zscore_entry <= zscore_exit or not selected_pairs_dict:\n",
    "        return no_update\n",
    "    else:\n",
    "        selected_pairs_dict = run_backtest(selected_pairs_dict=selected_pairs_dict,\n",
    "                                           zscore_entry=zscore_entry,\n",
    "                                           zscore_exit=zscore_exit)\n",
    "\n",
    "        # Build table with relevant data for stock pairs and convert to format compatible for dash_table.DataTable\n",
    "        selected_pairs_df = pd.DataFrame()\n",
    "        for dict_ in selected_pairs_dict.values():\n",
    "            dict_selected_keys = {key: [dict_[key]] for key in ['SymbolA', 'SymbolB', 'Corr', 'Half-Life', 'Sharpe', 'CAGR (%)']}\n",
    "            df_temp = pd.DataFrame.from_dict(dict_selected_keys)\n",
    "            selected_pairs_df = selected_pairs_df.append(df_temp)\n",
    "        selected_pairs_df.reset_index(inplace=True, drop=True)\n",
    "        selected_pairs_df = selected_pairs_df.round(3)\n",
    "        selected_pairs_dash_table_data = selected_pairs_df.to_dict('records')\n",
    "        selected_pairs_dash_table_columns = [{\"name\": i, \"id\": i} for i in selected_pairs_df.columns]\n",
    "        \n",
    "        backtest_table_descr = 'Select row/pair in table to compute full risk/return metrics (please change selection to refresh full-metrics table if you update z-score values):'\n",
    "    \n",
    "    return selected_pairs_dict, backtest_table_descr, selected_pairs_dash_table_data, selected_pairs_dash_table_columns\n",
    "\n",
    "\n",
    "@app.callback(Output('backtest-details-table-descr', 'children'),\n",
    "              Output('backtest-details-table', 'data'),\n",
    "              Output('backtest-details-table', 'columns'),\n",
    "              Output('cumulative-return-plot', 'figure'),\n",
    "              Output('zscore-plot', 'figure'),\n",
    "              State('browser-session-memory-storage', 'data'),\n",
    "              Input(\"backtest-table\", \"selected_rows\"),\n",
    "              prevent_initial_call=True\n",
    "             )\n",
    "def run_backtest_details_callback(selected_pairs_dict, selected_pair):\n",
    "    # Extract pair of stocks from dictionary and store values in selected_pair_dict to compute all risk/return metrics (detailed backtest) and charts\n",
    "    selected_pair_dict = list(selected_pairs_dict.values())[selected_pair[0]]\n",
    "    \n",
    "    # Deserialize JSON pandas series stored in dict\n",
    "    df_cumret = pd.read_json(selected_pair_dict['cumulative_return'], typ='series')\n",
    "    df_cumret_frame = df_cumret.to_frame('cumulative_return')\n",
    "    df_cumret_frame['cumulative_return'] = 100*(df_cumret_frame['cumulative_return'] - 1)\n",
    "    df_cumret_frame.index.names = ['Date']\n",
    "\n",
    "    fig1 = px.line(df_cumret_frame, x=df_cumret_frame.index, y=df_cumret_frame['cumulative_return'])\n",
    "    \n",
    "    # Deserialize JSON pandas series stored in dict\n",
    "    df_stock_a = pd.read_json(selected_pair_dict['x'], typ='series').to_frame('StockA')\n",
    "    df_stock_b = pd.read_json(selected_pair_dict['y'], typ='series').to_frame('StockB')\n",
    "    df_stock_a.index.names = ['Date']\n",
    "    df_stock_b.index.names = ['Date']\n",
    "    df_stock = pd.merge(df_stock_a, df_stock_b, on='Date')\n",
    "    df_stock_zscore = pd.read_json(selected_pair_dict['zscore'], typ='series').to_frame('zscore')\n",
    "    df_stock_zscore.index.names = ['Date']\n",
    "    df_stock = pd.merge(df_stock, df_stock_zscore, on='Date')\n",
    "    df_stock['rolling_correlation'] = df_stock['StockA'].rolling(10).corr(df_stock['StockB'])\n",
    "\n",
    "    fig2 = px.line(df_stock, x=df_stock.index, y=['zscore', 'rolling_correlation'])\n",
    "    \n",
    "    risk_return_metrics = run_backtest_details(df_cumret=df_cumret)\n",
    "    risk_return_metrics_dash_table_data = risk_return_metrics.to_dict('records')\n",
    "    risk_return_metrics_dash_table_columns = [{\"name\": i, \"id\": i} for i in risk_return_metrics.columns]\n",
    "    \n",
    "    backtest_details_table_descr = 'Full risk/return metrics:'\n",
    "\n",
    "    return backtest_details_table_descr, risk_return_metrics_dash_table_data, risk_return_metrics_dash_table_columns, fig1, fig2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d343a617-be26-452c-97d7-7c2754e3985e",
   "metadata": {},
   "source": [
    "# Project-2: Multi-Variate Index Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61eb580-98eb-483b-8fc4-a04c57d2296e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-08T14:47:46.803103Z",
     "iopub.status.busy": "2023-08-08T14:47:46.802768Z",
     "iopub.status.idle": "2023-08-08T14:47:47.389926Z",
     "shell.execute_reply": "2023-08-08T14:47:47.389283Z",
     "shell.execute_reply.started": "2023-08-08T14:47:46.803086Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f9ee388f220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dash import Dash, html, dcc, Input, Output, State, callback, no_update\n",
    "from dash_dangerously_set_inner_html import DangerouslySetInnerHTML\n",
    "import dash_mantine_components as dmc\n",
    "import plotly.express as px\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "db_params={'db_uri': 'mongodb://localhost:27017/',\n",
    "           'db_name': 'stocks_db',\n",
    "           'db_collection_name': 'daily'}\n",
    "db_uri = db_params['db_uri']\n",
    "db_name = db_params['db_name']\n",
    "db_collection_name = db_params['db_collection_name']\n",
    "        \n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(db_uri)\n",
    "db = client[db_name]\n",
    "db_collection = db[db_collection_name]  # Get/create collection for specific type of stocks data (daily, monthly, etc.)\n",
    "\n",
    "\n",
    "def get_all_index_symbols(db_collection):\n",
    "    \"\"\"\n",
    "    Get list of stock index symbols stored in the database\n",
    "    \"\"\"\n",
    "    index_symbols = [elem.replace('Index_','^') for elem in list(db_collection.find_one().keys()) if elem.startswith('Index_')]\n",
    "    # Database query to extract pairs {'Symbol', 'Name'} for each Index Symbol in the database\n",
    "    cursor = db_collection.aggregate([{\"$match\": {\"Symbol\": {\"$in\": index_symbols}\n",
    "                                             }\n",
    "                                  },\n",
    "                                  { '$group': {'_id'   : '$Symbol',\n",
    "                                               'Symbol': { '$first': '$Symbol' },\n",
    "                                               'Name'  : { '$first': '$Name'   }\n",
    "                                              }\n",
    "                                  },\n",
    "                                  { '$project': {'_id':     0,\n",
    "                                                 'Symbol':  1,\n",
    "                                                 'Name':    1,\n",
    "                                                }\n",
    "                                  }\n",
    "                                 ])\n",
    "    query_result = list(cursor)\n",
    "    # Transform pairs {'Symbol', 'Name'} into full strying, ex. convert {^NDX, NASDAQ 100} into '^NDX - NASDAQ 100'\n",
    "    index_symbols_names = [f'{value1} - {value2}' for value1, value2 in [list(dict_.values()) for dict_ in query_result]]\n",
    "    return index_symbols_names\n",
    "\n",
    "\n",
    "def extract_index_symbol(selected_index_symbol_name: str):\n",
    "    \"\"\"\n",
    "    Extract Index Symbol from string combination 'Index_Symbol - Index_Name' (ex. get ^NDX from '^NDX - NASDAQ 100')\n",
    "    \"\"\"\n",
    "    selected_index_symbol = selected_index_symbol_name.split(' - ', 1)[0]\n",
    "    return selected_index_symbol\n",
    "\n",
    "\n",
    "def extract_stock_symbols(selected_stock_symbols_names: list):\n",
    "    \"\"\"\n",
    "    Extract Symbols from list of strings combinations ['Stock_Symbol_1 - Stock_Name_1', 'Stock_Symbol_2 - Stock_Name_2', ...]\n",
    "    ex. get ['ZM', 'ZS', 'XEL', ...] from ['ZM - Zoom Video Communications, Inc.', 'ZS - Zscaler, Inc.', 'XEL - Xcel Energy Inc.', ...]\n",
    "    \"\"\"\n",
    "    selected_stock_symbols = [selected_stock_symbol_name.split(' - ', 1)[0] for selected_stock_symbol_name in selected_stock_symbols_names]\n",
    "    return selected_stock_symbols\n",
    "\n",
    "\n",
    "def get_all_stocks_for_index(selected_index_symbol):\n",
    "    \"\"\"\n",
    "    Get list of all stocks (stored in the database) for a specific stock index symbol\n",
    "    \"\"\"\n",
    "    selected_index_symbol = selected_index_symbol.replace('^', '')\n",
    "    # Query database to get all stocks contained in an index\n",
    "    cursor = db_collection.aggregate([{ '$match' : { f'Index_{selected_index_symbol}': True}\n",
    "                                      }, \n",
    "                                      { '$group': {'_id'   : '$Symbol',\n",
    "                                                   'Symbol': { '$first': '$Symbol' },\n",
    "                                                   'Name'  : { '$first': '$Name'   }\n",
    "                                                  }\n",
    "                                      },\n",
    "                                      { '$project': {'_id':     0,\n",
    "                                                     'Symbol':  1,\n",
    "                                                     'Name':    1,\n",
    "                                                    }\n",
    "                                      }\n",
    "                                     ])\n",
    "    query_result = list(cursor)\n",
    "    return query_result\n",
    "\n",
    "\n",
    "def get_stock_index_data(selected_index_symbol):\n",
    "    \"\"\"\n",
    "    Get data (from the database) for a specific stock index symbol\n",
    "    \"\"\"\n",
    "    # Query database to get closing prices for selected stock index:\n",
    "    selected_index_cursor = db_collection.find({ 'Symbol': selected_index_symbol },\n",
    "                                                     {'_id':    0,\n",
    "                                                      'Date':   1,\n",
    "                                                      'Symbol': 1,\n",
    "                                                      'Close': 1\n",
    "                                                     }\n",
    "                                                     )\n",
    "    query_result_selected_index = list(selected_index_cursor)\n",
    "    # Build pandas dataframe with stock index data got from database.\n",
    "    # ex. \n",
    "    #    Date (df index)         ^GSPC (stock index symbol)\n",
    "    #    2023-07-25 04:00:00     4567.459961\n",
    "    #    2023-07-26 04:00:00     4566.750000\n",
    "    #    2023-07-27 04:00:00     4537.410156\n",
    "    #    2023-07-28 04:00:00     4582.229980\n",
    "    #    2023-07-31 04:00:00     4588.959961\n",
    "    #    2023-08-01 04:00:00     4577.919922\n",
    "    #\n",
    "    data_stock_index = pd.DataFrame(query_result_selected_index)\n",
    "    data_stock_index = data_stock_index.rename(columns={'Close': data_stock_index['Symbol'].iloc[0]})\n",
    "    data_stock_index.drop(columns=['Symbol'], inplace=True)\n",
    "    \n",
    "    return data_stock_index\n",
    "\n",
    "def get_stocks_data(selected_stock_symbols):\n",
    "    \"\"\"\n",
    "    Get data (from the database) for a list of stock symbols\n",
    "    \"\"\"\n",
    "    # Query database to get closing prices for selected stocks:\n",
    "    selected_stocks_cursor = db_collection.find({ 'Symbol': {\"$in\": selected_stock_symbols}},\n",
    "                                                     {'_id':    0,\n",
    "                                                      'Date':   1,\n",
    "                                                      'Symbol': 1,\n",
    "                                                      'Close': 1\n",
    "                                                     }\n",
    "                                                     )\n",
    "    query_result_selected_stocks = list(selected_stocks_cursor)\n",
    "    # Build pandas dataframe with stocks data got from database (structure it to have name of column containing closing price for specific stock, equal to the symbol of the stock)\n",
    "    # ex. \n",
    "    #    Date  (df index)       XEL          ZM           ZS => stock symbols \n",
    "    #    2023-07-25 04:00:00    64.959999    69.330002    155.210007\n",
    "    #    2023-07-26 04:00:00    65.050003    71.099998    156.619995\n",
    "    #    2023-07-27 04:00:00    62.869999    72.389999    155.250000\n",
    "    #    2023-07-28 04:00:00    62.889999    73.080002    157.490005\n",
    "    #    2023-07-31 04:00:00    62.730000    73.349998    160.380005\n",
    "    #    2023-08-01 04:00:00    62.930000    72.485001    163.940002\n",
    "    #\n",
    "    data_stocks_query = pd.DataFrame(query_result_selected_stocks)\n",
    "    gb = data_stocks_query.groupby('Symbol')\n",
    "    data_stocks = pd.DataFrame()\n",
    "    for x in gb.groups:\n",
    "        if data_stocks.empty:\n",
    "            df_temp = gb.get_group(x)\n",
    "            df_temp = df_temp.rename(columns={'Close': df_temp['Symbol'].iloc[0]})\n",
    "            df_temp.drop(columns=['Symbol'], inplace=True)\n",
    "            data_stocks = df_temp\n",
    "            del df_temp\n",
    "        else:\n",
    "            df_temp = gb.get_group(x)\n",
    "            df_temp = df_temp.rename(columns={'Close': df_temp['Symbol'].iloc[0]})\n",
    "            df_temp.drop(columns=['Symbol'], inplace=True)\n",
    "            data_stocks = pd.merge(data_stocks, df_temp, on='Date')\n",
    "            del df_temp\n",
    "    \n",
    "    return data_stocks\n",
    "\n",
    "\n",
    "app.layout = dmc.MantineProvider(\n",
    "    theme={\n",
    "        #\"fontFamily\": \"'Inter', sans-serif\",\n",
    "        \"primaryColor\": \"indigo\",\n",
    "        \"components\": {\n",
    "            \"Button\": {\"styles\": {\"root\": {\"fontWeight\": 400}}},\n",
    "            \"Alert\": {\"styles\": {\"title\": {\"fontWeight\": 500}}},\n",
    "            \"AvatarGroup\": {\"styles\": {\"truncated\": {\"fontWeight\": 500}}},\n",
    "         },\n",
    "    },\n",
    "    inherit=True,\n",
    "    withGlobalStyles=True,\n",
    "    withNormalizeCSS=True,\n",
    "    children=[\n",
    "    dmc.Space(h=20),\n",
    "    dmc.Grid([\n",
    "        dmc.Col([dmc.Title(f\"Multi-Variate Index Regression\", order=4),\n",
    "                 dmc.Select(label='Select Stock Index',\n",
    "                            placeholder='You can select only 1 stock index',\n",
    "                            id='stock-indices-dropdown',\n",
    "                            data=get_all_index_symbols(db_collection=db_collection),\n",
    "                            value='^NDX - NASDAQ 100',\n",
    "                            style={\"width\": 300}\n",
    "                           ),\n",
    "                 dmc.MultiSelect(label='Select Stocks',\n",
    "                                 description='You can select between 1 and 10 stocks',\n",
    "                                 id='stocks-dropdown',\n",
    "                                 #value=['ZM - Zoom Video Communications, Inc.'],\n",
    "                                 value=[],\n",
    "                                 maxSelectedValues=10,\n",
    "                                 style={\"width\": 300},\n",
    "                                 clearable=True,\n",
    "                                 searchable=True),\n",
    "                 dmc.Space(h=10),\n",
    "                 dmc.Alert(\"Unfortunately there was a problem in \\nestimating the regression model with the \\nselected stocks probably for lack of data \\nfor some symbols. Please remove the last \\nselected stock(s) from the box or try a different group of stocks.\",\n",
    "                           id='regression-model-alert',\n",
    "                           title=\"ALERT!\",\n",
    "                           color=\"red\",\n",
    "                           duration=5000,\n",
    "                           hide=True,\n",
    "                           style={\"width\": 350,\n",
    "                                  \"white-space\": \"pre\"}),\n",
    "                 dmc.Space(h=30),\n",
    "                 dmc.Text('Press the below button to automatically select the \\nstocks (10 or less) that best explain the index \\n(selected above):',\n",
    "                          align=\"left\",\n",
    "                          size=\"sm\",\n",
    "                          style={\"width\": 350,\n",
    "                                 \"white-space\": \"pre\"}),\n",
    "                 dmc.Button(\"Select Best Stocks\", id='button-best-stocks'),\n",
    "                 dmc.Space(h=10),\n",
    "                 dmc.Alert(\"I'm Selecting the Stocks! Please wait.\",\n",
    "                           id='computing-stock-selection-alert',\n",
    "                           title=\"INFO\",\n",
    "                           color=\"yellow\",\n",
    "                           hide=True),\n",
    "                 dmc.Space(h=10),\n",
    "                 dmc.Alert(\"Unfortunately there was a problem in \\nselecting the stocks that best explain \\nthe index. \\nPlease select them manually in the box.\",\n",
    "                           id='best-stocks-alert',\n",
    "                           title=\"ALERT!\",\n",
    "                           color=\"red\",\n",
    "                           duration=5000,\n",
    "                           hide=True,\n",
    "                           style={\"width\": 350,\n",
    "                                  \"white-space\": \"pre\"}),\n",
    "                ], span=3, offset=0.25),\n",
    "        dmc.Col([dcc.Graph(figure={}, id=\"scatter-plot\"),\n",
    "                ], span=5, offset=-0.75),\n",
    "        dmc.Col([html.Div(id='ols-summary-table'),\n",
    "                ], span=4),\n",
    "    ]),\n",
    "])\n",
    "\n",
    "@app.callback(Output('stocks-dropdown', 'data'),\n",
    "              Output('ols-summary-table', 'children'),\n",
    "              Output('scatter-plot', 'figure'),\n",
    "              Input('stock-indices-dropdown', 'value'),\n",
    "              prevent_initial_call=True)\n",
    "def get_all_stocks_for_index_callback(selected_index_symbol_name):\n",
    "    selected_index_symbol = extract_index_symbol(selected_index_symbol_name)\n",
    "    query_result = get_all_stocks_for_index(selected_index_symbol=selected_index_symbol)\n",
    "\n",
    "    # Convert list of stock symbols into list of strings in the format 'Stock_Symbol - Company_Name' (ex. 'ZM - Zoom Video Communications, Inc.' for symbol 'ZM') and drop Index Symbol from list\n",
    "    symbols_names = [value for value in [f'{value1} - {value2}' for value1, value2 in [list(dict_.values()) for dict_ in query_result]] if value != selected_index_symbol_name]\n",
    "    # Reset OLS regression model results table\n",
    "    ols_table_children = []\n",
    "    # Reset scatterplot figure\n",
    "    figure = {}\n",
    "    return symbols_names, ols_table_children, figure\n",
    "\n",
    "\n",
    "@app.callback(Output(\"stocks-dropdown\", \"error\"),\n",
    "              Input(\"stocks-dropdown\", \"value\"))\n",
    "def select_value(value):\n",
    "    return \"Select at least 1 stock\" if len(value) < 1 else \"\"\n",
    "\n",
    "\n",
    "@app.callback(Output('ols-summary-table', 'children', allow_duplicate=True),\n",
    "              Output('scatter-plot', 'figure', allow_duplicate=True),\n",
    "              Output(\"regression-model-alert\", \"hide\"),\n",
    "              State('stock-indices-dropdown', 'value'),\n",
    "              Input('stocks-dropdown', 'value'),\n",
    "              State(\"regression-model-alert\", \"hide\"),\n",
    "              prevent_initial_call=True)\n",
    "def multiple_linear_regression(selected_index_symbol_name, selected_stock_symbols_names, hide):\n",
    "    # Make sure the list of symbols is not empty\n",
    "    if not selected_stock_symbols_names:\n",
    "        return DangerouslySetInnerHTML('''<br>'''), {}, hide\n",
    "    \n",
    "    # Query database for data\n",
    "    # Query for stock index data\n",
    "    selected_index_symbol = extract_index_symbol(selected_index_symbol_name)\n",
    "    data_stock_index = get_stock_index_data(selected_index_symbol=selected_index_symbol)\n",
    "    # Query for stocks data\n",
    "    selected_stock_symbols = extract_stock_symbols(selected_stock_symbols_names)\n",
    "    data_stocks = get_stocks_data(selected_stock_symbols=selected_stock_symbols)\n",
    "    \n",
    "    # Fill NANs by forward filling\n",
    "    data_stock_index.ffill(inplace=True)\n",
    "    data_stocks.ffill(inplace=True)\n",
    "    \n",
    "    # Make sure the dataframes for the stock index and the single stocks have the same samples to avoid problems in the estimation of the regression model\n",
    "    data_stock_index = pd.merge(data_stock_index, data_stocks[['Date']], how='inner', on='Date')\n",
    "    data_stocks = pd.merge(data_stock_index[['Date']], data_stocks, how='inner', on='Date')\n",
    "    \n",
    "    # Set 'Date' as index on both dataframes\n",
    "    data_stock_index.set_index('Date', inplace=True)\n",
    "    data_stocks.set_index('Date', inplace=True)\n",
    "    \n",
    "    try:\n",
    "        y = data_stock_index\n",
    "        # define predictor variables\n",
    "        x = data_stocks\n",
    "        # add constant to predictor variables\n",
    "        x = sm.add_constant(x)\n",
    "        # fit linear regression model (I drop missing values)\n",
    "        model = sm.OLS(y, x, missing='drop').fit()\n",
    "\n",
    "        predictions = model.predict(x).to_frame()\n",
    "        predictions.rename(columns={predictions.columns[0]:'model_prediction'}, inplace=True)\n",
    "        df = pd.merge(y, predictions, on='Date')\n",
    "\n",
    "        fig = px.scatter(df, x=\"model_prediction\", y=selected_index_symbol)\n",
    "        result = model.summary().as_html()\n",
    "        result = DangerouslySetInnerHTML(result)\n",
    "        \n",
    "        return result, fig, hide\n",
    "    except:\n",
    "        hide = False\n",
    "        return no_update, no_update, hide\n",
    "\n",
    "\n",
    "@app.callback(Output(\"computing-stock-selection-alert\", \"hide\", allow_duplicate=True),\n",
    "              Input(\"button-best-stocks\", \"n_clicks\"),\n",
    "              State(\"computing-stock-selection-alert\", \"hide\"),\n",
    "              prevent_initial_call=True)\n",
    "def button_pressed_callback(n_clicks_button, hide_computing_stock_selection_alert):\n",
    "    hide_computing_stock_selection_alert = False\n",
    "    return hide_computing_stock_selection_alert\n",
    "\n",
    "\n",
    "@app.callback(Output('stocks-dropdown', 'value', allow_duplicate=True),\n",
    "              Output(\"best-stocks-alert\", \"hide\"),\n",
    "              Output(\"computing-stock-selection-alert\", \"hide\"),\n",
    "              State('stock-indices-dropdown', 'value'),\n",
    "              Input(\"button-best-stocks\", \"n_clicks\"),\n",
    "              State(\"best-stocks-alert\", \"hide\"),\n",
    "              State(\"computing-stock-selection-alert\", \"hide\"),\n",
    "              prevent_initial_call=True)\n",
    "def select_10_best_stocks(selected_index_symbol_name, n_clicks, hide_best_stocks_alert, hide_computing_stock_selection_alert):\n",
    "    # Query database for data\n",
    "    selected_index_symbol = extract_index_symbol(selected_index_symbol_name)\n",
    "    data_stock_index = get_stock_index_data(selected_index_symbol=selected_index_symbol)\n",
    "    \n",
    "    # Query for stocks data:\n",
    "    # Get all stock symbols for selected stock index.\n",
    "    # Query result will contain a list like:\n",
    "    #  [{'Symbol': 'ZM', 'Name': 'Zoom Video Communications, Inc.'},\n",
    "    #   {'Symbol': 'ZS', 'Name': 'Zscaler, Inc.'},\n",
    "    #   {'Symbol': '^NDX', 'Name': 'NASDAQ 100'},\n",
    "    #   {'Symbol': 'XEL', 'Name': 'Xcel Energy Inc.'},\n",
    "    #   ...]\n",
    "    query_result = get_all_stocks_for_index(selected_index_symbol=selected_index_symbol)\n",
    "    stock_index_symbol_name_list = get_all_index_symbols(db_collection=db_collection)\n",
    "    stock_index_symbols_list = [extract_index_symbol(stock_index_symbol_name) for stock_index_symbol_name in stock_index_symbol_name_list]\n",
    "    # Make sure to remove stock index symbol from list of stocks\n",
    "    selected_stock_symbols = [symbol_name_dict['Symbol'] for symbol_name_dict in query_result if symbol_name_dict['Symbol'] not in stock_index_symbols_list]\n",
    "    data_stocks = get_stocks_data(selected_stock_symbols=selected_stock_symbols)\n",
    "    \n",
    "    # Fill NANs by forward filling\n",
    "    data_stock_index.ffill(inplace=True)\n",
    "    data_stocks.ffill(inplace=True)\n",
    "    \n",
    "    # Make sure the dataframes for the stock index and the single stocks have the same samples to avoid problems in the estimation of the regression model\n",
    "    data_stock_index = pd.merge(data_stock_index, data_stocks[['Date']], how='inner', on='Date')\n",
    "    data_stocks = pd.merge(data_stock_index[['Date']], data_stocks, how='inner', on='Date')\n",
    "    \n",
    "    # Set 'Date' as index on both dataframes\n",
    "    data_stock_index.set_index('Date', inplace=True)\n",
    "    data_stocks.set_index('Date', inplace=True)\n",
    "    \n",
    "    try:\n",
    "        feature_selection = 'SelectFromModel'\n",
    "        #feature_selection = 'SequentialFeatureSelector'\n",
    "        \n",
    "        # Select the best 10 stocks/features (or less)\n",
    "        if feature_selection == 'SelectFromModel':\n",
    "            # Feature/stock selection done using an XGBoost model and the SelectFromModel function from scikit-learn (it uses the feature importance from the model passed as parameter)\n",
    "            # I use some preset hyperparameters' values for the XGBoost but a grid search could be applied to optimize these hyperparameters for the specific problem (e.g., by using bayesian hyperparameter\n",
    "            # optimization, random grid search or a full grid search)\n",
    "            # https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html\n",
    "            model = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                                     booster='gbtree',\n",
    "                                     n_estimators=100,\n",
    "                                     random_state=42,\n",
    "                                     n_jobs=-1)\n",
    "            sfm_selector = SelectFromModel(estimator=model,\n",
    "                                           max_features=10,  # we want to select max 10 features\n",
    "                                           prefit=False)\n",
    "            sfm_selector.fit(X=data_stocks,\n",
    "                             y=data_stock_index.values.ravel())\n",
    "            best_stocks = sfm_selector.get_feature_names_out()\n",
    "        elif feature_selection == 'SequentialFeatureSelector':\n",
    "            # Feature/stock selection done with the SequentialFeatureSelector. This method adds (forward selection) or removes (backward selection) features to form a feature subset in a greedy fashion.\n",
    "            # It should give better results than the SelectFromModel approach but it takes longer to execute, in particular if the number of stocks/features is of decent size.\n",
    "            # I use a linear regression model to speed up the computation.\n",
    "            # https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html\n",
    "            model = LinearRegression()\n",
    "            # We want to select 10 features/stocks if possible but if there are less in the dataset we set the 'n_features_to_select' variable to 'auto'\n",
    "            if data_stocks.shape[1] < 10:\n",
    "                n_features_to_select = 'auto'\n",
    "            else:\n",
    "                n_features_to_select = 10\n",
    "            sfs_selector = SequentialFeatureSelector(estimator=model,\n",
    "                                                     n_features_to_select=n_features_to_select,\n",
    "                                                     tol=None,\n",
    "                                                     direction='forward',\n",
    "                                                     #direction='backward',\n",
    "                                                     scoring='r2',\n",
    "                                                     n_jobs=-1)\n",
    "            sfs_selector.fit(X=data_stocks,\n",
    "                             y=data_stock_index.values.ravel())\n",
    "            best_stocks = sfs_selector.get_feature_names_out()\n",
    "\n",
    "        # Once we have selected the best stocks as list (e.g., ['ZM', 'ZS', 'XEL', ...]) we build back the list containing the stock names as well\n",
    "        # (e.g., ['ZM - Zoom Video Communications, Inc.', 'ZS - Zscaler, Inc.', 'XEL - Xcel Energy Inc.', ...]) and pass this to the Dash component with id 'stocks-dropdown'\n",
    "        # which will trigger the callback to estimate the linear regression model.\n",
    "        \n",
    "        # Get stock names linked to stock symbols\n",
    "        best_stocks_symbols_names_list_of_dict = [symbol_name_dict for symbol_name_dict in query_result if symbol_name_dict['Symbol'] in best_stocks]\n",
    "        # Convert list of stock symbols into list of strings in the format 'Stock_Symbol - Company_Name' (ex. 'ZM - Zoom Video Communications, Inc.' for symbol 'ZM') and drop Index Symbol from list\n",
    "        best_stocks_symbols_names_list = [value for value in [f'{value1} - {value2}' for value1, value2 in [list(dict_.values()) for dict_ in best_stocks_symbols_names_list_of_dict]]]\n",
    "\n",
    "        hide_computing_stock_selection_alert = True\n",
    "        return best_stocks_symbols_names_list, hide_best_stocks_alert, hide_computing_stock_selection_alert\n",
    "    except:\n",
    "        hide_computing_stock_selection_alert = True\n",
    "        hide_best_stocks_alert = False\n",
    "        return no_update, hide_best_stocks_alert, hide_computing_stock_selection_alert\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38_bluecrest3]",
   "language": "python",
   "name": "conda-env-py38_bluecrest3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
